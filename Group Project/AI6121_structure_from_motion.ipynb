{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4tfzOZCMGLC",
        "outputId": "87bec79d-2cea-4831-d50f-2d1d1a1d4527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.6)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (10.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.8.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.6)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (75.1.0)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.8.30)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.5 jedi-0.19.1 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 widgetsnbextension-4.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import itertools\n",
        "\n",
        "# photoDiretory = 'drive/MyDrive/NTU photos/Dimsum01/Lowest Res/'\n",
        "photoDiretory = 'drive/MyDrive/NTU photos/Sculpture02/Seq/'\n",
        "\n",
        "images = [\n",
        "    cv2.imread(photoDiretory + '01.jpg'),\n",
        "    cv2.imread(photoDiretory + '02.jpg'),\n",
        "    cv2.imread(photoDiretory + '03.jpg'),\n",
        "    cv2.imread(photoDiretory + '04.jpg'),\n",
        "    cv2.imread(photoDiretory + '05.jpg'),\n",
        "    cv2.imread(photoDiretory + '06.jpg')\n",
        "]\n",
        "\n",
        "\n",
        "K = np.array([[2862.07,0,1802.81],[0,2860.28,1363.97],[0,0,1]])\n"
      ],
      "metadata": {
        "id": "xm8EKjyzmSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to define a \"good baseline\"\n",
        "# MIN_BASELINE_DISTANCE = 0.1   # Minimum translation distance between camera centers\n",
        "# MIN_ANGLE = 5                 # Minimum angular separation in degrees\n",
        "\n",
        "# # Detect and match features\n",
        "# def detect_and_match_features(img1, img2):\n",
        "#     sift = cv2.SIFT_create()\n",
        "#     kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "#     kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "\n",
        "#     # Feature matching using FLANN matcher\n",
        "#     matcher = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=50))\n",
        "#     matches = matcher.knnMatch(des1, des2, k=2)\n",
        "\n",
        "#     # Filter matches using Lowe's ratio test\n",
        "#     good_matches = []\n",
        "#     pts1, pts2 = [], []\n",
        "#     for m, n in matches:\n",
        "#         if m.distance < 0.75 * n.distance:\n",
        "#             pts1.append(kp1[m.queryIdx].pt)\n",
        "#             pts2.append(kp2[m.trainIdx].pt)\n",
        "#             good_matches.append(m)\n",
        "\n",
        "#     pts1 = np.float32(pts1)\n",
        "#     pts2 = np.float32(pts2)\n",
        "#     return pts1, pts2, good_matches\n",
        "\n",
        "# # Calculate translation and angular distance\n",
        "# def calculate_baseline_metrics(pts1, pts2, K):\n",
        "#     E, _ = cv2.findEssentialMat(pts1, pts2, K, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
        "#     _, R, t, _ = cv2.recoverPose(E, pts1, pts2, K)\n",
        "\n",
        "#     # Calculate baseline distance (norm of translation vector)\n",
        "#     baseline_distance = np.linalg.norm(t)\n",
        "\n",
        "#     # Calculate rotation angle between cameras (in degrees)\n",
        "#     angle = np.degrees(np.arccos((np.trace(R) - 1) / 2))\n",
        "\n",
        "#     return baseline_distance, angle\n",
        "\n",
        "# # Filter image pairs with a \"good baseline\"\n",
        "# good_baseline_pairs = []\n",
        "# for (i, img1), (j, img2) in itertools.combinations(enumerate(images), 2):\n",
        "#     pts1, pts2, matches = detect_and_match_features(img1, img2)\n",
        "#     if len(matches) > 8:  # Ensure there are enough matches to estimate the pose\n",
        "#         baseline_distance, angle = calculate_baseline_metrics(pts1, pts2, K)\n",
        "\n",
        "#         # Check if the pair meets baseline criteria\n",
        "#         if baseline_distance >= MIN_BASELINE_DISTANCE and angle >= MIN_ANGLE:\n",
        "#             good_baseline_pairs.append((i, j, baseline_distance, angle))\n",
        "\n",
        "# # Print the selected pairs\n",
        "# for i, j, dist, ang in good_baseline_pairs:\n",
        "#     print(f\"Image pair ({i}, {j}) has a good baseline: Distance = {dist:.2f}, Angle = {ang:.2f} degrees\")\n",
        "\n",
        "# for \"Dimsum01/Lowest Res/*\", the best baseline is 1, 9 jpeg, 1, 3 is next\n",
        "#"
      ],
      "metadata": {
        "id": "vbuJc7lXEvUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make the first two images to be the best baseline\n",
        "# tmp = images[1]\n",
        "# images[1] = images[8]\n",
        "# images[8] = tmp"
      ],
      "metadata": {
        "id": "ZKc9j-pQzCyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "class View:\n",
        "    \"\"\"Represents an image used in the reconstruction\"\"\"\n",
        "    def __init__(self, image, image_name, root_path, feature_path, feature_type='sift'):\n",
        "        self.image = image  # list of images in the view\n",
        "        self.name = image_name\n",
        "        self.keypoints = []  # list of keypoints obtained from feature extraction\n",
        "        self.descriptors = []  # list of descriptors obtained from feature extraction\n",
        "        self.feature_type = feature_type  # feature extraction method\n",
        "        self.root_path = root_path  # root directory containing the image folder\n",
        "        self.R = np.zeros((3, 3), dtype=float)  # rotation matrix for the view\n",
        "        self.t = np.zeros((3, 1), dtype=float)  # translation vector for the view\n",
        "\n",
        "        if not feature_path:\n",
        "            self.extract_features()\n",
        "        else:\n",
        "            self.read_features()\n",
        "\n",
        "    def extract_features(self):\n",
        "        \"\"\"Extracts features from the image\"\"\"\n",
        "        if self.feature_type == 'sift':\n",
        "            detector = cv2.xfeatures2d.SIFT_create()\n",
        "        elif self.feature_type == 'surf':\n",
        "            detector = cv2.xfeatures2d.SURF_create()\n",
        "        elif self.feature_type == 'orb':\n",
        "            detector = cv2.ORB_create(nfeatures=1500)\n",
        "        else:\n",
        "            print(\"Admitted feature types are SIFT, SURF or ORB\")\n",
        "            return\n",
        "\n",
        "        self.keypoints, self.descriptors = detector.detectAndCompute(self.image, None)\n",
        "        print(\"Computed features for image \", self.name)\n",
        "\n",
        "        self.write_features()\n",
        "\n",
        "    def read_features(self):\n",
        "        \"\"\"Reads features stored in files. Feature files have filenames corresponding to image names without extensions\"\"\"\n",
        "\n",
        "        # logic to compute features for images that don't have pkl files\n",
        "        try:\n",
        "            features = pickle.load(open(os.path.join(self.root_path, 'features', self.name + '.pkl'), \"rb\"))\n",
        "            print(\"Read features from file for image \", self.name)\n",
        "\n",
        "            keypoints = []\n",
        "            descriptors = []\n",
        "\n",
        "            for point in features:\n",
        "                keypoint = cv2.KeyPoint(x=point[0][0], y=point[0][1], size=point[1], angle=point[2],\n",
        "                                        response=point[3], octave=point[4], class_id=point[5])\n",
        "                descriptor = point[6]\n",
        "                keypoints.append(keypoint)\n",
        "                descriptors.append(descriptor)\n",
        "\n",
        "            self.keypoints = keypoints\n",
        "            self.descriptors = np.array(descriptors)  # convert descriptors into n x 128 numpy array\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"Pkl file not found for image \", self.name, \" Computing from scratch\")\n",
        "            self.extract_features()\n",
        "\n",
        "    def write_features(self):\n",
        "        \"\"\"Stores computed features to pkl files. The files are written inside a features directory inside the root directory\"\"\"\n",
        "\n",
        "        if not os.path.exists(os.path.join(self.root_path, 'features')):\n",
        "            os.makedirs(os.path.join(self.root_path, 'features'))\n",
        "\n",
        "        temp_array = []\n",
        "        for idx, point in enumerate(self.keypoints):\n",
        "            temp = (point.pt, point.size, point.angle, point.response, point.octave, point.class_id,\n",
        "                    self.descriptors[idx])\n",
        "            temp_array.append(temp)\n",
        "\n",
        "        features_file = open(os.path.join(self.root_path, 'features', self.name + '.pkl'), 'wb')\n",
        "        pickle.dump(temp_array, features_file)\n",
        "        features_file.close()\n"
      ],
      "metadata": {
        "id": "uP3lBZNozvCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_path = False\n",
        "\n",
        "# if features directory exists, the feature files are read from there\n",
        "if os.path.exists(os.path.join(photoDiretory, 'features')):\n",
        "  feature_path = True\n",
        "\n",
        "print(\"Computing features\")\n",
        "views = []\n",
        "for i in range(len(images)):\n",
        "  views.append(View(images[i], str(i), photoDiretory, feature_path=feature_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8KAgAT4GwZn",
        "outputId": "9c91851f-7f54-4774-f71f-9f6e1cbbcd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing features\n",
            "Computed features for image  0\n",
            "Computed features for image  1\n",
            "Computed features for image  2\n",
            "Computed features for image  3\n",
            "Computed features for image  4\n",
            "Computed features for image  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Match:\n",
        "    \"\"\"Represents a feature matches between two views\"\"\"\n",
        "\n",
        "    def __init__(self, view1, view2, match_path):\n",
        "\n",
        "        self.indices1 = []  # indices of the matched keypoints in the first view\n",
        "        self.indices2 = []  # indices of the matched keypoints in the second view\n",
        "        self.distances = []  # distance between the matched keypoints in the first view\n",
        "        self.image_name1 = view1.name  # name of the first view\n",
        "        self.image_name2 = view2.name  # name of the second view\n",
        "        self.root_path = view1.root_path  # root directory containing the image folder\n",
        "        self.inliers1 = []  # list to store the indices of the keypoints from the first view not removed using the fundamental matrix\n",
        "        self.inliers2 = []  # list to store the indices of the keypoints from the second view not removed using the fundamental matrix\n",
        "        self.view1 = view1\n",
        "        self.view2 = view2\n",
        "\n",
        "        if view1.feature_type in ['sift', 'surf']:\n",
        "            self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "        else:\n",
        "            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "        if not match_path:\n",
        "            self.get_matches(view1, view2)\n",
        "        else:\n",
        "            self.read_matches()\n",
        "\n",
        "    def get_matches(self, view1, view2):\n",
        "        \"\"\"Extracts feature matches between two views\"\"\"\n",
        "\n",
        "        matches = self.matcher.match(view1.descriptors, view2.descriptors)\n",
        "        matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "        # store match components in their respective lists\n",
        "        for i in range(len(matches)):\n",
        "            self.indices1.append(matches[i].queryIdx)\n",
        "            self.indices2.append(matches[i].trainIdx)\n",
        "            self.distances.append(matches[i].distance)\n",
        "\n",
        "        print(\"Computed matches between view \", self.image_name1, \" and view \", self.image_name2)\n",
        "\n",
        "        self.write_matches()\n",
        "\n",
        "    def write_matches(self):\n",
        "        \"\"\"Writes a match to a pkl file in the root_path/matches directory\"\"\"\n",
        "\n",
        "        if not os.path.exists(os.path.join(self.root_path, 'matches')):\n",
        "            os.makedirs(os.path.join(self.root_path, 'matches'))\n",
        "\n",
        "        temp_array = []\n",
        "        for i in range(len(self.indices1)):\n",
        "            temp = (self.distances[i], self.indices1[i], self.indices2[i])\n",
        "            temp_array.append(temp)\n",
        "\n",
        "        matches_file = open(os.path.join(self.root_path, 'matches', self.image_name1 + '_' + self.image_name2 + '.pkl'), 'wb')\n",
        "        pickle.dump(temp_array, matches_file)\n",
        "        matches_file.close()\n",
        "\n",
        "    def read_matches(self):\n",
        "        \"\"\"Reads matches from file\"\"\"\n",
        "\n",
        "        try:\n",
        "            matches = pickle.load(\n",
        "                open(\n",
        "                    os.path.join(self.root_path, 'matches', self.image_name1 + '_' + self.image_name2 + '.pkl'),\n",
        "                    \"rb\"\n",
        "                )\n",
        "            )\n",
        "            print(\"Read matches from file for view pair pair\", self.image_name1, self.image_name2)\n",
        "\n",
        "            for point in matches:\n",
        "                self.distances.append(point[0])\n",
        "                self.indices1.append(point[1])\n",
        "                self.indices2.append(point[2])\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"Pkl file not found for match \", self.image_name1, self.image_name2,\". Computing from scratch\", )\n",
        "            self.get_matches(self.view1, self.view2)\n",
        "\n"
      ],
      "metadata": {
        "id": "-CdZeVR0HgUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_path = False\n",
        "\n",
        "if os.path.exists(os.path.join(photoDiretory, 'matches')):\n",
        "    match_path = True\n",
        "\n",
        "matches = {}\n",
        "for i in range(0, len(views) - 1):\n",
        "    for j in range(i+1, len(views)):\n",
        "        matches[(views[i].name, views[j].name)] = Match(views[i], views[j], match_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w75bF7DEIMJ9",
        "outputId": "7eb8e126-1f00-4b2d-e4e1-003bdd167c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed matches between view  0  and view  1\n",
            "Computed matches between view  0  and view  2\n",
            "Computed matches between view  0  and view  3\n",
            "Computed matches between view  0  and view  4\n",
            "Computed matches between view  0  and view  5\n",
            "Computed matches between view  1  and view  2\n",
            "Computed matches between view  1  and view  3\n",
            "Computed matches between view  1  and view  4\n",
            "Computed matches between view  1  and view  5\n",
            "Computed matches between view  2  and view  3\n",
            "Computed matches between view  2  and view  4\n",
            "Computed matches between view  2  and view  5\n",
            "Computed matches between view  3  and view  4\n",
            "Computed matches between view  3  and view  5\n",
            "Computed matches between view  4  and view  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keypoints_from_indices(keypoints1, index_list1, keypoints2, index_list2):\n",
        "    \"\"\"Filters a list of keypoints based on the indices given\"\"\"\n",
        "\n",
        "    points1 = np.array([kp.pt for kp in keypoints1])[index_list1]\n",
        "    points2 = np.array([kp.pt for kp in keypoints2])[index_list2]\n",
        "    return points1, points2\n",
        "\n",
        "\n",
        "def get_3D_point(u1, P1, u2, P2):\n",
        "    \"\"\"Solves for 3D point using homogeneous 2D points and the respective camera matrices\"\"\"\n",
        "\n",
        "    A = np.array([[u1[0] * P1[2, 0] - P1[0, 0], u1[0] * P1[2, 1] - P1[0, 1], u1[0] * P1[2, 2] - P1[0, 2]],\n",
        "                  [u1[1] * P1[2, 0] - P1[1, 0], u1[1] * P1[2, 1] - P1[1, 1], u1[1] * P1[2, 2] - P1[1, 2]],\n",
        "                  [u2[0] * P2[2, 0] - P2[0, 0], u2[0] * P2[2, 1] - P2[0, 1], u2[0] * P2[2, 2] - P2[0, 2]],\n",
        "                  [u2[1] * P2[2, 0] - P2[1, 0], u2[1] * P2[2, 1] - P2[1, 1], u2[1] * P2[2, 2] - P2[1, 2]]])\n",
        "\n",
        "    B = np.array([-(u1[0] * P1[2, 3] - P1[0, 3]),\n",
        "                  -(u1[1] * P1[2, 3] - P1[1, 3]),\n",
        "                  -(u2[0] * P2[2, 3] - P2[0, 3]),\n",
        "                  -(u2[1] * P2[2, 3] - P2[1, 3])])\n",
        "\n",
        "    X = cv2.solve(A, B, flags=cv2.DECOMP_SVD)\n",
        "    return X[1]\n",
        "\n",
        "\n",
        "def remove_outliers_using_F(view1, view2, match_object):\n",
        "    \"\"\"Removes outlier keypoints using the fundamental matrix\"\"\"\n",
        "\n",
        "    pixel_points1, pixel_points2 = get_keypoints_from_indices(keypoints1=view1.keypoints,\n",
        "                                                              keypoints2=view2.keypoints,\n",
        "                                                              index_list1=match_object.indices1,\n",
        "                                                              index_list2=match_object.indices2)\n",
        "    F, mask = cv2.findFundamentalMat(pixel_points1, pixel_points2, method=cv2.FM_RANSAC,\n",
        "                                     ransacReprojThreshold=0.9, confidence=0.99)\n",
        "    mask = mask.astype(bool).flatten()\n",
        "    match_object.inliers1 = np.array(match_object.indices1)[mask]\n",
        "    match_object.inliers2 = np.array(match_object.indices2)[mask]\n",
        "\n",
        "    return F\n",
        "\n",
        "\n",
        "def calculate_reprojection_error(point_3D, point_2D, K, R, t):\n",
        "    \"\"\"Calculates the reprojection error for a 3D point by projecting it back into the image plane\"\"\"\n",
        "\n",
        "    reprojected_point = K.dot(R.dot(point_3D) + t)\n",
        "    reprojected_point = cv2.convertPointsFromHomogeneous(reprojected_point.T)[:, 0, :].T\n",
        "    error = np.linalg.norm(point_2D.reshape((2, 1)) - reprojected_point)\n",
        "    return error\n",
        "\n",
        "\n",
        "def get_camera_from_E(E):\n",
        "    \"\"\"Calculates rotation and translation component from essential matrix\"\"\"\n",
        "\n",
        "    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
        "    W_t = W.T\n",
        "    u, w, vt = np.linalg.svd(E)\n",
        "\n",
        "    R1 = u @ W @ vt\n",
        "    R2 = u @ W_t @ vt\n",
        "    t1 = u[:, -1].reshape((3, 1))\n",
        "    t2 = - t1\n",
        "    return R1, R2, t1, t2\n",
        "\n",
        "\n",
        "def check_determinant(R):\n",
        "    \"\"\"Validates using the determinant of the rotation matrix\"\"\"\n",
        "\n",
        "    if np.linalg.det(R) + 1.0 < 1e-9:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "def check_triangulation(points, P):\n",
        "    \"\"\"Checks whether reconstructed points lie in front of the camera\"\"\"\n",
        "\n",
        "    P = np.vstack((P, np.array([0, 0, 0, 1])))\n",
        "    reprojected_points = cv2.perspectiveTransform(src=points[np.newaxis], m=P)\n",
        "    z = reprojected_points[0, :, -1]\n",
        "    if (np.sum(z > 0)/z.shape[0]) < 0.75:\n",
        "        return False\n",
        "    else:\n",
        "        return True"
      ],
      "metadata": {
        "id": "VGVVR-uxLJ52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline:\n",
        "    \"\"\"Represents the functions that compute the baseline pose from the initial images of a reconstruction\"\"\"\n",
        "\n",
        "    def __init__(self, view1, view2, match_object):\n",
        "\n",
        "        self.view1 = view1  # first view\n",
        "        self.view1.R = np.eye(3, 3)  # identity rotation since the first view is said to be at the origin\n",
        "        self.view2 = view2  # second view\n",
        "        self.match_object = match_object  # match object between first and second view\n",
        "\n",
        "    def get_pose(self, K):\n",
        "        \"\"\"Computes and returns the rotation and translation components for the second view\"\"\"\n",
        "\n",
        "        F = remove_outliers_using_F(self.view1, self.view2, self.match_object)\n",
        "        E = K.T @ F @ K  # compute the essential matrix from the fundamental matrix\n",
        "        print(\"Computed essential matrix\")\n",
        "        print(\"Choosing correct pose out of 4 solutions\")\n",
        "\n",
        "        return self.check_pose(E, K)\n",
        "\n",
        "    def check_pose(self, E, K):\n",
        "        \"\"\"Retrieves the rotation and translation components from the essential matrix by decomposing it and verifying the validity of the 4 possible solutions\"\"\"\n",
        "\n",
        "        R1, R2, t1, t2 = get_camera_from_E(E)  # decompose E\n",
        "        if not check_determinant(R1):\n",
        "            R1, R2, t1, t2 = get_camera_from_E(-E)  # change sign of E if R1 fails the determinant test\n",
        "\n",
        "        # solution 1\n",
        "        reprojection_error, points_3D = self.triangulate(K, R1, t1)\n",
        "        # check if reprojection is not faulty and if the points are correctly triangulated in the front of the camera\n",
        "        if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R1, t1))):\n",
        "\n",
        "            # solution 2\n",
        "            reprojection_error, points_3D = self.triangulate(K, R1, t2)\n",
        "            if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R1, t2))):\n",
        "\n",
        "                # solution 3\n",
        "                reprojection_error, points_3D = self.triangulate(K, R2, t1)\n",
        "                if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R2, t1))):\n",
        "\n",
        "                    # solution 4\n",
        "                    return R2, t2\n",
        "\n",
        "                else:\n",
        "                    return R2, t1\n",
        "\n",
        "            else:\n",
        "                return R1, t2\n",
        "\n",
        "        else:\n",
        "            return R1, t1\n",
        "\n",
        "    def triangulate(self, K, R, t):\n",
        "        \"\"\"Triangulate points between the baseline views and calculates the mean reprojection error of the triangulation\"\"\"\n",
        "\n",
        "        K_inv = np.linalg.inv(K)\n",
        "        P1 = np.hstack((self.view1.R, self.view1.t))\n",
        "        P2 = np.hstack((R, t))\n",
        "\n",
        "        # only reconstructs the inlier points filtered using the fundamental matrix\n",
        "        pixel_points1, pixel_points2 = get_keypoints_from_indices(keypoints1=self.view1.keypoints,\n",
        "                                                                  keypoints2=self.view2.keypoints,\n",
        "                                                                  index_list1=self.match_object.inliers1,\n",
        "                                                                  index_list2=self.match_object.inliers2)\n",
        "\n",
        "        # convert 2D pixel points to homogeneous coordinates\n",
        "        pixel_points1 = cv2.convertPointsToHomogeneous(pixel_points1)[:, 0, :]\n",
        "        pixel_points2 = cv2.convertPointsToHomogeneous(pixel_points2)[:, 0, :]\n",
        "\n",
        "        reprojection_error = []\n",
        "\n",
        "        points_3D = np.zeros((0, 3))  # stores the triangulated points\n",
        "\n",
        "        for i in range(len(pixel_points1)):\n",
        "            u1 = pixel_points1[i, :]\n",
        "            u2 = pixel_points2[i, :]\n",
        "\n",
        "            # convert homogeneous 2D points to normalized device coordinates\n",
        "            u1_normalized = K_inv.dot(u1)\n",
        "            u2_normalized = K_inv.dot(u2)\n",
        "\n",
        "            # calculate 3D point\n",
        "            point_3D = get_3D_point(u1_normalized, P1, u2_normalized, P2)\n",
        "\n",
        "            # calculate reprojection error\n",
        "            error = calculate_reprojection_error(point_3D, u2[0:2], K, R, t)\n",
        "            reprojection_error.append(error)\n",
        "\n",
        "            # append point\n",
        "            points_3D = np.concatenate((points_3D, point_3D.T), axis=0)\n",
        "\n",
        "        return np.mean(reprojection_error), points_3D"
      ],
      "metadata": {
        "id": "0kxiPLqcLR4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "\n",
        "class SFM:\n",
        "    \"\"\"Represents the main reconstruction loop\"\"\"\n",
        "\n",
        "    def __init__(self, views, matches, K):\n",
        "\n",
        "        self.views = views  # list of views\n",
        "        self.matches = matches  # dictionary of matches\n",
        "        self.names = []  # image names\n",
        "        self.done = []  # list of views that have been reconstructed\n",
        "        self.K = K  # intrinsic matrix\n",
        "        self.points_3D = np.zeros((0, 3))  # reconstructed 3D points\n",
        "        self.point_counter = 0  # keeps track of the reconstructed points\n",
        "        self.point_map = {}  # a dictionary of the 2D points that contributed to a given 3D point\n",
        "        self.errors = []  # list of mean reprojection errors taken at the end of every new view being added\n",
        "\n",
        "        for view in self.views:\n",
        "            self.names.append(view.name)\n",
        "\n",
        "        if not os.path.exists(self.views[0].root_path + '/points'):\n",
        "            os.makedirs(self.views[0].root_path + '/points')\n",
        "\n",
        "        # store results in a root_path/points\n",
        "        self.results_path = os.path.join(self.views[0].root_path, 'points')\n",
        "\n",
        "    def get_index_of_view(self, view):\n",
        "        \"\"\"Extracts the position of a view in the list of views\"\"\"\n",
        "\n",
        "        return self.names.index(view.name)\n",
        "\n",
        "    def remove_mapped_points(self, match_object, image_idx):\n",
        "        \"\"\"Removes points that have already been reconstructed in the completed views\"\"\"\n",
        "\n",
        "        inliers1 = []\n",
        "        inliers2 = []\n",
        "\n",
        "        for i in range(len(match_object.inliers1)):\n",
        "            if (image_idx, match_object.inliers1[i]) not in self.point_map:\n",
        "                inliers1.append(match_object.inliers1[i])\n",
        "                inliers2.append(match_object.inliers2[i])\n",
        "\n",
        "        match_object.inliers1 = inliers1\n",
        "        match_object.inliers2 = inliers2\n",
        "\n",
        "    def compute_pose(self, view1, view2=None, is_baseline=False):\n",
        "        \"\"\"Computes the pose of the new view\"\"\"\n",
        "\n",
        "        # procedure for baseline pose estimation\n",
        "        if is_baseline and view2:\n",
        "\n",
        "            match_object = self.matches[(view1.name, view2.name)]\n",
        "            baseline_pose = Baseline(view1, view2, match_object)\n",
        "            view2.R, view2.t = baseline_pose.get_pose(self.K)\n",
        "\n",
        "            rpe1, rpe2 = self.triangulate(view1, view2)\n",
        "            self.errors.append(np.mean(rpe1))\n",
        "            self.errors.append(np.mean(rpe2))\n",
        "\n",
        "            self.done.append(view1)\n",
        "            self.done.append(view2)\n",
        "\n",
        "        # procedure for estimating the pose of all other views\n",
        "        else:\n",
        "\n",
        "            view1.R, view1.t = self.compute_pose_PNP(view1)\n",
        "            errors = []\n",
        "\n",
        "            # reconstruct unreconstructed points from all of the previous views\n",
        "            for i, old_view in enumerate(self.done):\n",
        "\n",
        "                match_object = self.matches[(old_view.name, view1.name)]\n",
        "                _ = remove_outliers_using_F(old_view, view1, match_object)\n",
        "                self.remove_mapped_points(match_object, i)\n",
        "                _, rpe = self.triangulate(old_view, view1)\n",
        "                errors += rpe\n",
        "\n",
        "            self.done.append(view1)\n",
        "            self.errors.append(np.mean(errors))\n",
        "\n",
        "    def triangulate(self, view1, view2):\n",
        "        \"\"\"Triangulates 3D points from two views whose poses have been recovered. Also updates the point_map dictionary\"\"\"\n",
        "\n",
        "        K_inv = np.linalg.inv(self.K)\n",
        "        P1 = np.hstack((view1.R, view1.t))\n",
        "        P2 = np.hstack((view2.R, view2.t))\n",
        "\n",
        "        match_object = self.matches[(view1.name, view2.name)]\n",
        "        pixel_points1, pixel_points2 = get_keypoints_from_indices(keypoints1=view1.keypoints,\n",
        "                                                                  keypoints2=view2.keypoints,\n",
        "                                                                  index_list1=match_object.inliers1,\n",
        "                                                                  index_list2=match_object.inliers2)\n",
        "        pixel_points1 = cv2.convertPointsToHomogeneous(pixel_points1)[:, 0, :]\n",
        "        pixel_points2 = cv2.convertPointsToHomogeneous(pixel_points2)[:, 0, :]\n",
        "        reprojection_error1 = []\n",
        "        reprojection_error2 = []\n",
        "\n",
        "        for i in range(len(pixel_points1)):\n",
        "\n",
        "            u1 = pixel_points1[i, :]\n",
        "            u2 = pixel_points2[i, :]\n",
        "\n",
        "            u1_normalized = K_inv.dot(u1)\n",
        "            u2_normalized = K_inv.dot(u2)\n",
        "\n",
        "            point_3D = get_3D_point(u1_normalized, P1, u2_normalized, P2)\n",
        "            self.points_3D = np.concatenate((self.points_3D, point_3D.T), axis=0)\n",
        "\n",
        "            error1 = calculate_reprojection_error(point_3D, u1[0:2], self.K, view1.R, view1.t)\n",
        "            reprojection_error1.append(error1)\n",
        "            error2 = calculate_reprojection_error(point_3D, u2[0:2], self.K, view2.R, view2.t)\n",
        "            reprojection_error2.append(error2)\n",
        "\n",
        "            # updates point_map with the key (index of view, index of point in the view) and value point_counter\n",
        "            # multiple keys can have the same value because a 3D point is reconstructed using 2 points\n",
        "            self.point_map[(self.get_index_of_view(view1), match_object.inliers1[i])] = self.point_counter\n",
        "            self.point_map[(self.get_index_of_view(view2), match_object.inliers2[i])] = self.point_counter\n",
        "            self.point_counter += 1\n",
        "\n",
        "        return reprojection_error1, reprojection_error2\n",
        "\n",
        "    def compute_pose_PNP(self, view):\n",
        "        \"\"\"Computes pose of new view using perspective n-point\"\"\"\n",
        "\n",
        "        if view.feature_type in ['sift', 'surf']:\n",
        "            matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
        "        else:\n",
        "            matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "\n",
        "        # collects all the descriptors of the reconstructed views\n",
        "        old_descriptors = []\n",
        "        for old_view in self.done:\n",
        "            old_descriptors.append(old_view.descriptors)\n",
        "\n",
        "        # match old descriptors against the descriptors in the new view\n",
        "        matcher.add(old_descriptors)\n",
        "        matcher.train()\n",
        "        matches = matcher.match(queryDescriptors=view.descriptors)\n",
        "        points_3D, points_2D = np.zeros((0, 3)), np.zeros((0, 2))\n",
        "\n",
        "        # build corresponding array of 2D points and 3D points\n",
        "        for match in matches:\n",
        "            old_image_idx, new_image_kp_idx, old_image_kp_idx = match.imgIdx, match.queryIdx, match.trainIdx\n",
        "\n",
        "            if (old_image_idx, old_image_kp_idx) in self.point_map:\n",
        "\n",
        "                # obtain the 2D point from match\n",
        "                point_2D = np.array(view.keypoints[new_image_kp_idx].pt).T.reshape((1, 2))\n",
        "                points_2D = np.concatenate((points_2D, point_2D), axis=0)\n",
        "\n",
        "                # obtain the 3D point from the point_map\n",
        "                point_3D = self.points_3D[self.point_map[(old_image_idx, old_image_kp_idx)], :].T.reshape((1, 3))\n",
        "                points_3D = np.concatenate((points_3D, point_3D), axis=0)\n",
        "\n",
        "        # compute new pose using solvePnPRansac\n",
        "        _, R, t, _ = cv2.solvePnPRansac(points_3D[:, np.newaxis], points_2D[:, np.newaxis], self.K, None,\n",
        "                                        confidence=0.99, reprojectionError=8.0, flags=cv2.SOLVEPNP_DLS)\n",
        "        R, _ = cv2.Rodrigues(R)\n",
        "        return R, t\n",
        "\n",
        "    def plot_points(self):\n",
        "        \"\"\"Saves the reconstructed 3D points to ply files using Open3D\"\"\"\n",
        "\n",
        "        number = len(self.done)\n",
        "        filename = os.path.join(self.results_path, str(number) + '_images.ply')\n",
        "        pcd = o3d.geometry.PointCloud()\n",
        "        pcd.points = o3d.utility.Vector3dVector(self.points_3D)\n",
        "        o3d.io.write_point_cloud(filename, pcd)\n",
        "\n",
        "    def reconstruct(self):\n",
        "        \"\"\"Starts the main reconstruction loop for a given set of views and matches\"\"\"\n",
        "\n",
        "        # compute baseline pose\n",
        "        baseline_view1, baseline_view2 = self.views[0], self.views[1]\n",
        "        print(\"Computing baseline pose and reconstructing points\")\n",
        "        self.compute_pose(view1=baseline_view1, view2=baseline_view2, is_baseline=True)\n",
        "        print(\"Mean reprojection error for 1 image is \", self.errors[0])\n",
        "        print(\"Mean reprojection error for 2 images is \", self.errors[1])\n",
        "        self.plot_points()\n",
        "        print(\"Points plotted for \", len(self.done), \" views\")\n",
        "\n",
        "        for i in range(2, len(self.views)):\n",
        "\n",
        "            print(\"Computing pose and reconstructing points for view \", i+1)\n",
        "            self.compute_pose(view1=self.views[i])\n",
        "            print(\"Mean reprojection error for \", i+1, \" images is \", self.errors[i])\n",
        "            self.plot_points()\n",
        "            print(\"Points plotted for \", i+1, \" views\")"
      ],
      "metadata": {
        "id": "MGQjRp7eKP-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfm = SFM(views, matches, K)\n",
        "sfm.reconstruct()\n"
      ],
      "metadata": {
        "id": "T7ze04lXambP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e328829-5c71-466f-9e6f-074252b1ec81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing baseline pose and reconstructing points\n",
            "Computed essential matrix\n",
            "Choosing correct pose out of 4 solutions\n",
            "Mean reprojection error for 1 image is  98.10002132343392\n",
            "Mean reprojection error for 2 images is  96.99156986152738\n",
            "Points plotted for  2  views\n",
            "Computing pose and reconstructing points for view  3\n",
            "Mean reprojection error for  3  images is  498.8724971564826\n",
            "Points plotted for  3  views\n",
            "Computing pose and reconstructing points for view  4\n",
            "Mean reprojection error for  4  images is  480.5156156605757\n",
            "Points plotted for  4  views\n",
            "Computing pose and reconstructing points for view  5\n",
            "Mean reprojection error for  5  images is  16037.982094849329\n",
            "Points plotted for  5  views\n",
            "Computing pose and reconstructing points for view  6\n",
            "Mean reprojection error for  6  images is  48.04739584268121\n",
            "Points plotted for  6  views\n"
          ]
        }
      ]
    }
  ]
}